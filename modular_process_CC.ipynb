{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1b3f05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data loading...\n",
      "Converting center coordinates (27.783611, -97.414779) to UTM...\n",
      "Corpus Christi center in UTM (EPSG:32614): (656184.519263486, 3074239.5261650323)\n",
      "- Checking cache for blocks...\n",
      "Loading data from cache: cache\\blocks.pkl\n",
      "- Checking cache for buildings...\n",
      "-- Fetching building data...\n",
      "-- Raw buildings dataset columns:\n",
      "Index(['geometry', 'addr:state', 'building', 'ele', 'gnis:feature_id', 'name',\n",
      "       'source', 'addr:city', 'addr:housename', 'addr:housenumber',\n",
      "       ...\n",
      "       'check_date:opening_hours:drive_through', 'fuel:octane_87',\n",
      "       'fuel:octane_89', 'fuel:octane_93', 'female', 'male', 'portable',\n",
      "       'toilets:handwashing', 'capacity', 'size'],\n",
      "      dtype='object', length=198)\n",
      "-- Preview of raw building dataset:\n",
      "                                      geometry addr:state    building  ele  \\\n",
      "element id                                                                   \n",
      "node    368160094   POINT (-97.39638 27.79725)         TX         yes   10   \n",
      "        368164119    POINT (-97.39573 27.8072)         TX       house    1   \n",
      "        368164527   POINT (-97.39694 27.78753)         TX         yes   11   \n",
      "        368164702   POINT (-97.39587 27.80718)         TX       house    1   \n",
      "        2462108137  POINT (-97.50309 27.80249)        NaN  industrial  NaN   \n",
      "\n",
      "                   gnis:feature_id                        name         source  \\\n",
      "element id                                                                      \n",
      "node    368160094          2031465  Broadway Bluff Improvement  USGS Geonames   \n",
      "        368164119          2031422     Charlotte Sidbury House  USGS Geonames   \n",
      "        368164527          2031675          Richard King House  USGS Geonames   \n",
      "        368164702          2032681                      S Juli  USGS Geonames   \n",
      "        2462108137             NaN   Pathfinder energy service            NaN   \n",
      "\n",
      "                         addr:city             addr:housename  \\\n",
      "element id                                                      \n",
      "node    368160094              NaN                        NaN   \n",
      "        368164119              NaN                        NaN   \n",
      "        368164527              NaN                        NaN   \n",
      "        368164702              NaN                        NaN   \n",
      "        2462108137  corpus christi  Pathfinder Energy Service   \n",
      "\n",
      "                   addr:housenumber  ...  \\\n",
      "element id                           ...   \n",
      "node    368160094               NaN  ...   \n",
      "        368164119               NaN  ...   \n",
      "        368164527               NaN  ...   \n",
      "        368164702               NaN  ...   \n",
      "        2462108137             1111  ...   \n",
      "\n",
      "                   check_date:opening_hours:drive_through fuel:octane_87  \\\n",
      "element id                                                                 \n",
      "node    368160094                                     NaN            NaN   \n",
      "        368164119                                     NaN            NaN   \n",
      "        368164527                                     NaN            NaN   \n",
      "        368164702                                     NaN            NaN   \n",
      "        2462108137                                    NaN            NaN   \n",
      "\n",
      "                   fuel:octane_89 fuel:octane_93 female male portable  \\\n",
      "element id                                                              \n",
      "node    368160094             NaN            NaN    NaN  NaN      NaN   \n",
      "        368164119             NaN            NaN    NaN  NaN      NaN   \n",
      "        368164527             NaN            NaN    NaN  NaN      NaN   \n",
      "        368164702             NaN            NaN    NaN  NaN      NaN   \n",
      "        2462108137            NaN            NaN    NaN  NaN      NaN   \n",
      "\n",
      "                   toilets:handwashing capacity size  \n",
      "element id                                            \n",
      "node    368160094                  NaN      NaN  NaN  \n",
      "        368164119                  NaN      NaN  NaN  \n",
      "        368164527                  NaN      NaN  NaN  \n",
      "        368164702                  NaN      NaN  NaN  \n",
      "        2462108137                 NaN      NaN  NaN  \n",
      "\n",
      "[5 rows x 198 columns]\n",
      "-- Focusing on the 'height' column for building heights...\n",
      "-- 'height' column found. Attempting numerical conversion...\n",
      "-- Valid height values: 89242 / Total: 102671 (86.92%)\n",
      "-- Converted 'height' values to numeric. Example values:\n",
      "element  id        \n",
      "node     368160094     NaN\n",
      "         368164119     NaN\n",
      "         368164527     NaN\n",
      "         368164702     NaN\n",
      "         2462108137    NaN\n",
      "Name: height, dtype: object\n",
      "-- Reprojecting buildings to EPSG:32614...\n",
      "Saving data to cache: cache\\buildings.pkl\n",
      "- Checking cache for roads...\n",
      "Loading data from cache: cache\\roads.pkl\n",
      "- Subsampling datasets...\n",
      "- Subsampling data using bounding box...\n",
      "-- Bounding box geometry: POLYGON ((657708.519263486 3072715.5261650323, 657708.519263486 3075763.5261650323, 654660.519263486 3075763.5261650323, 654660.519263486 3072715.5261650323, 657708.519263486 3072715.5261650323))\n",
      "-- Blocks CRS: EPSG:32614\n",
      "-- Buildings CRS before reprojection: EPSG:32614\n",
      "-- Roads CRS: EPSG:32614\n",
      "-- Buildings CRS after reprojection: EPSG:32614\n",
      "-- Buildings subset shape after intersects: (6896, 198)\n",
      "-- Subsampled 534 blocks, 6896 buildings, and 2227 roads.\n",
      "- Data loading complete.\n",
      "-- Blocks subset:\n",
      "       STATEFP20 COUNTYFP20 TRACTCE20 BLOCKCE20          GEOID20  \\\n",
      "211081        48        355    001300      4003  483550013004003   \n",
      "211082        48        355    001300      4004  483550013004004   \n",
      "211084        48        355    001400      1007  483550014001007   \n",
      "211085        48        355    001400      1006  483550014001006   \n",
      "211086        48        355    001400      1005  483550014001005   \n",
      "\n",
      "                       GEOIDFQ20     NAME20 MTFCC20 UR20 UACE20 FUNCSTAT20  \\\n",
      "211081  1000000US483550013004003  Block4003   G5040    U  20287          S   \n",
      "211082  1000000US483550013004004  Block4004   G5040    U  20287          S   \n",
      "211084  1000000US483550014001007  Block1007   G5040    U  20287          S   \n",
      "211085  1000000US483550014001006  Block1006   G5040    U  20287          S   \n",
      "211086  1000000US483550014001005  Block1005   G5040    U  20287          S   \n",
      "\n",
      "        ALAND20  AWATER20   INTPTLAT20    INTPTLON20  HOUSING20  POP20  \\\n",
      "211081    24467         0  +27.7697013  -097.4050378         32     77   \n",
      "211082    17105         0  +27.7691166  -097.4057168          0      0   \n",
      "211084    15131         0  +27.7719254  -097.4019975          2      3   \n",
      "211085     5446         0  +27.7726786  -097.4014717          0      0   \n",
      "211086     2066         0  +27.7728600  -097.4010085          0      0   \n",
      "\n",
      "                                                 geometry  \n",
      "211081  POLYGON ((657076.274 3072786.758, 657080.514 3...  \n",
      "211082  POLYGON ((657029.407 3072699.161, 657058.753 3...  \n",
      "211084  POLYGON ((657380.777 3073004.915, 657463.483 3...  \n",
      "211085  POLYGON ((657463.483 3073057.297, 657549.725 3...  \n",
      "211086  POLYGON ((657549.725 3073110.613, 657555.997 3...  \n",
      "-- Buildings subset:\n",
      "                                                             geometry  \\\n",
      "element  id                                                             \n",
      "relation 7628821    POLYGON ((657297.973 3072889.324, 657296.617 3...   \n",
      "         7631335    POLYGON ((655971.44 3073866.272, 655976.652 30...   \n",
      "         7631337    POLYGON ((657180.987 3075375.442, 657183.062 3...   \n",
      "way      203372431  POLYGON ((655993.713 3075574.793, 655980.011 3...   \n",
      "         261460863  POLYGON ((657557.379 3075528.374, 657561.735 3...   \n",
      "\n",
      "                   addr:state  building  ele gnis:feature_id  \\\n",
      "element  id                                                    \n",
      "relation 7628821          NaN       yes  NaN             NaN   \n",
      "         7631335          NaN  hospital  NaN             NaN   \n",
      "         7631337          NaN       yes  NaN             NaN   \n",
      "way      203372431        NaN       yes  NaN             NaN   \n",
      "         261460863         TX    office    9         2030565   \n",
      "\n",
      "                                        name source addr:city addr:housename  \\\n",
      "element  id                                                                    \n",
      "relation 7628821                         NaN    NaN       NaN            NaN   \n",
      "         7631335                         NaN    NaN       NaN            NaN   \n",
      "         7631337                         NaN    NaN       NaN            NaN   \n",
      "way      203372431                       NaN    NaN       NaN            NaN   \n",
      "         261460863  Nueces County Courthouse   Bing       NaN            NaN   \n",
      "\n",
      "                   addr:housenumber  ...  \\\n",
      "element  id                          ...   \n",
      "relation 7628821                NaN  ...   \n",
      "         7631335                NaN  ...   \n",
      "         7631337                NaN  ...   \n",
      "way      203372431              NaN  ...   \n",
      "         261460863              NaN  ...   \n",
      "\n",
      "                   check_date:opening_hours:drive_through fuel:octane_87  \\\n",
      "element  id                                                                \n",
      "relation 7628821                                      NaN            NaN   \n",
      "         7631335                                      NaN            NaN   \n",
      "         7631337                                      NaN            NaN   \n",
      "way      203372431                                    NaN            NaN   \n",
      "         261460863                                    NaN            NaN   \n",
      "\n",
      "                   fuel:octane_89 fuel:octane_93 female male portable  \\\n",
      "element  id                                                             \n",
      "relation 7628821              NaN            NaN    NaN  NaN      NaN   \n",
      "         7631335              NaN            NaN    NaN  NaN      NaN   \n",
      "         7631337              NaN            NaN    NaN  NaN      NaN   \n",
      "way      203372431            NaN            NaN    NaN  NaN      NaN   \n",
      "         261460863            NaN            NaN    NaN  NaN      NaN   \n",
      "\n",
      "                   toilets:handwashing capacity size  \n",
      "element  id                                           \n",
      "relation 7628821                   NaN      NaN  NaN  \n",
      "         7631335                   NaN      NaN  NaN  \n",
      "         7631337                   NaN      NaN  NaN  \n",
      "way      203372431                 NaN      NaN  NaN  \n",
      "         261460863                 NaN      NaN  NaN  \n",
      "\n",
      "[5 rows x 198 columns]\n",
      "-- Roads subset:\n",
      "                             osmid      highway lanes             name  \\\n",
      "u         v         key                                                  \n",
      "227454545 227454551 0     21145794     tertiary   NaN  Highland Avenue   \n",
      "          227502421 0    371318831  residential   NaN      Ruth Street   \n",
      "          227502418 0    371318832     tertiary   NaN      Ruth Street   \n",
      "227454551 227454554 0     21145794     tertiary   NaN  Highland Avenue   \n",
      "          227536777 0     21160049  residential   NaN  Hibiscus Street   \n",
      "\n",
      "                         oneway  ref reversed      length maxspeed  \\\n",
      "u         v         key                                              \n",
      "227454545 227454551 0     False  NaN    False  117.941931      NaN   \n",
      "          227502421 0     False  NaN    False   26.240267      NaN   \n",
      "          227502418 0     False  NaN     True   42.143124      NaN   \n",
      "227454551 227454554 0     False  NaN    False  152.238928      NaN   \n",
      "          227536777 0     False  NaN    False  166.763729      NaN   \n",
      "\n",
      "                                                                  geometry  \\\n",
      "u         v         key                                                      \n",
      "227454545 227454551 0    LINESTRING (655587.283 3074123.505, 655546.617...   \n",
      "          227502421 0    LINESTRING (655587.283 3074123.505, 655575.176...   \n",
      "          227502418 0    LINESTRING (655587.283 3074123.505, 655604.94 ...   \n",
      "227454551 227454554 0    LINESTRING (655495.562 3074049.411, 655374.926...   \n",
      "          227536777 0    LINESTRING (655495.562 3074049.411, 655501.252...   \n",
      "\n",
      "                        bridge junction width access  \n",
      "u         v         key                               \n",
      "227454545 227454551 0      NaN      NaN   NaN    NaN  \n",
      "          227502421 0      NaN      NaN   NaN    NaN  \n",
      "          227502418 0      NaN      NaN   NaN    NaN  \n",
      "227454551 227454554 0      NaN      NaN   NaN    NaN  \n",
      "          227536777 0      NaN      NaN   NaN    NaN  \n"
     ]
    }
   ],
   "source": [
    "import osmnx as ox\n",
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import os\n",
    "import pickle\n",
    "from shapely.geometry import box\n",
    "from pyproj import Transformer\n",
    "\n",
    "\n",
    "### Utility Functions ###\n",
    "def read_path_from_file(file_path: str) -> str:\n",
    "    \"\"\"Read OneDrive path from a text file.\"\"\"\n",
    "    try:\n",
    "        with open(file_path, \"r\") as file:\n",
    "            path = file.readline().strip()  # Read the first line and strip whitespace\n",
    "        return path\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{file_path}' does not exist.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return None\n",
    "\n",
    "\n",
    "def save_to_cache(data, filename, cache_dir=\"cache\"):\n",
    "    \"\"\"Save a GeoDataFrame or Python object to a pickle file in the cache directory.\"\"\"\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "    cache_path = os.path.join(cache_dir, filename)\n",
    "    print(f\"Saving data to cache: {cache_path}\")\n",
    "    with open(cache_path, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "\n",
    "\n",
    "def load_from_cache(filename, cache_dir=\"cache\"):\n",
    "    \"\"\"Load a GeoDataFrame or Python object from a pickle file in the cache directory.\"\"\"\n",
    "    cache_path = os.path.join(cache_dir, filename)\n",
    "    if os.path.exists(cache_path):\n",
    "        print(f\"Loading data from cache: {cache_path}\")\n",
    "        with open(cache_path, \"rb\") as f:\n",
    "            return pickle.load(f)\n",
    "    return None\n",
    "\n",
    "\n",
    "def latlon_to_utm(lat: float, lon: float, epsg: int = 32614):\n",
    "    \"\"\"\n",
    "    Convert latitude and longitude (EPSG:4326) to UTM coordinates (e.g., EPSG:32614).\n",
    "    \"\"\"\n",
    "    transformer = Transformer.from_crs(\"EPSG:4326\", f\"EPSG:{epsg}\", always_xy=True)\n",
    "    x, y = transformer.transform(lon, lat)  # Transform to target coordinates\n",
    "    return x, y\n",
    "\n",
    "\n",
    "def subsample_data(center_point: tuple, scale: float, blocks: gpd.GeoDataFrame, buildings: gpd.GeoDataFrame, roads: gpd.GeoDataFrame):\n",
    "    \"\"\"\n",
    "    Subsample blocks, buildings, and roads using a bounding box around a central point.\n",
    "    Ensures proper alignment of CRS before subsampling.\n",
    "    \"\"\"\n",
    "    print(\"- Subsampling data using bounding box...\")\n",
    "\n",
    "    # Default bounding box size: ~10,000 feet (~3,048 meters) on each side\n",
    "    default_bbox_size = 3048  # Half the total size on each dimension, in meters\n",
    "    scaled_bbox_size = default_bbox_size * scale\n",
    "\n",
    "    # Calculate bounding box geometry based on scaled size\n",
    "    center_x, center_y = center_point\n",
    "    bbox = box(\n",
    "        center_x - scaled_bbox_size,  # Min X\n",
    "        center_y - scaled_bbox_size,  # Min Y\n",
    "        center_x + scaled_bbox_size,  # Max X\n",
    "        center_y + scaled_bbox_size   # Max Y\n",
    "    )\n",
    "    print(\"-- Bounding box geometry:\", bbox)\n",
    "\n",
    "    # Debugging: Check CRS alignment for all datasets\n",
    "    print(\"-- Blocks CRS:\", blocks.crs)\n",
    "    print(\"-- Buildings CRS before reprojection:\", buildings.crs)\n",
    "    print(\"-- Roads CRS:\", roads.crs)\n",
    "\n",
    "    # Reproject buildings to match the CRS of the bounding box (EPSG:32614)\n",
    "    if buildings.crs.to_string().lower() != \"epsg:32614\":\n",
    "        print(\"-- Reprojecting buildings to EPSG:32614...\")\n",
    "        buildings = buildings.to_crs(epsg=32614)\n",
    "\n",
    "    print(\"-- Buildings CRS after reprojection:\", buildings.crs)\n",
    "\n",
    "    # Filter each GeoDataFrame by the bounding box intersection\n",
    "    blocks_subset = blocks[blocks.geometry.intersects(bbox)]\n",
    "    buildings_subset = buildings[buildings.geometry.intersects(bbox)]\n",
    "    roads_subset = roads[roads.geometry.intersects(bbox)]\n",
    "\n",
    "    # Debugging: Check if any buildings are retained in the subset\n",
    "    print(\"-- Buildings subset shape after intersects:\", buildings_subset.shape)\n",
    "    if len(buildings_subset) == 0:\n",
    "        print(\"-- Warning: No buildings found within the bounding box.\")\n",
    "        print(\"-- Original buildings dataset sample (after reprojection):\")\n",
    "        print(buildings.geometry.head())  # Inspect original geometries\n",
    "\n",
    "    print(f\"-- Subsampled {len(blocks_subset)} blocks, {len(buildings_subset)} buildings, and {len(roads_subset)} roads.\")\n",
    "    return blocks_subset, buildings_subset, roads_subset\n",
    "\n",
    "\n",
    "def load_data(block_path, osm_boundary_place, cache_dir=\"cache\", subsample_scale=1.0):\n",
    "    \"\"\"\n",
    "    Load blocks, buildings, and roads data from cache (if available), process, and optionally subsample using a scaled bounding box.\n",
    "    Uses only the 'height' column for building heights and outputs the percentage of valid values.\n",
    "    \"\"\"\n",
    "    # Corpus Christi center point from Google Maps\n",
    "    corpus_christi_lat = 27.783611  # Latitude\n",
    "    corpus_christi_lon = -97.414779  # Longitude\n",
    "\n",
    "    print(f\"Converting center coordinates ({corpus_christi_lat}, {corpus_christi_lon}) to UTM...\")\n",
    "    corpus_christi_center_utm = latlon_to_utm(corpus_christi_lat, corpus_christi_lon)  # Convert to UTM (EPSG:32614)\n",
    "    print(f\"Corpus Christi center in UTM (EPSG:32614): {corpus_christi_center_utm}\")\n",
    "\n",
    "    # Check cache for blocks\n",
    "    print(\"- Checking cache for blocks...\")\n",
    "    blocks = load_from_cache(\"blocks.pkl\", cache_dir)\n",
    "    if blocks is None:\n",
    "        print(\"-- Loading block data...\")\n",
    "        blocks = gpd.read_file(block_path).to_crs(epsg=32614)\n",
    "        blocks.loc[:, \"POP20\"] = pd.to_numeric(blocks[\"POP20\"], errors=\"coerce\")  # Explicitly use `.loc`\n",
    "        save_to_cache(blocks, \"blocks.pkl\", cache_dir)\n",
    "\n",
    "    # Check cache for buildings\n",
    "    print(\"- Checking cache for buildings...\")\n",
    "    buildings = load_from_cache(\"buildings.pkl\", cache_dir)\n",
    "    if buildings is None:\n",
    "        print(\"-- Fetching building data...\")\n",
    "        buildings = ox.features_from_place(\n",
    "            osm_boundary_place,\n",
    "            tags={\"building\": True, \"building:height\": True, \"building:levels\": True}\n",
    "        )\n",
    "\n",
    "        print(\"-- Raw buildings dataset columns:\")\n",
    "        print(buildings.columns)  # Print available columns for validation\n",
    "        print(\"-- Preview of raw building dataset:\")\n",
    "        print(buildings.head())  # Inspect raw data for possible errors\n",
    "\n",
    "        # Focus only on the 'height' column for building heights\n",
    "        print(\"-- Focusing on the 'height' column for building heights...\")\n",
    "        if \"height\" in buildings.columns:\n",
    "            print(\"-- 'height' column found. Attempting numerical conversion...\")\n",
    "            buildings.loc[:, \"height\"] = pd.to_numeric(buildings[\"height\"], errors=\"coerce\")\n",
    "\n",
    "            # Debugging: Calculate percentage of valid values (>0 and numeric)\n",
    "            total_height_values = len(buildings)\n",
    "            valid_height_values = buildings[\"height\"].dropna().gt(0).sum()\n",
    "            percentage_valid = (valid_height_values / total_height_values) * 100 if total_height_values > 0 else 0\n",
    "            print(f\"-- Valid height values: {valid_height_values} / Total: {total_height_values} ({percentage_valid:.2f}%)\")\n",
    "\n",
    "            print(\"-- Converted 'height' values to numeric. Example values:\")\n",
    "            print(buildings[\"height\"].head())\n",
    "        else:\n",
    "            print(\"-- ERROR: 'height' column is missing in the dataset! Setting height to None.\")\n",
    "            buildings.loc[:, \"height\"] = None\n",
    "\n",
    "        # Reproject buildings to CRS: EPSG:32614\n",
    "        print(\"-- Reprojecting buildings to EPSG:32614...\")\n",
    "        buildings = buildings.to_crs(epsg=32614)\n",
    "\n",
    "        # Save the buildings dataset to cache\n",
    "        save_to_cache(buildings, \"buildings.pkl\", cache_dir)\n",
    "\n",
    "    # Check cache for roads\n",
    "    print(\"- Checking cache for roads...\")\n",
    "    roads = load_from_cache(\"roads.pkl\", cache_dir)\n",
    "    if roads is None:\n",
    "        print(\"-- Fetching road data...\")\n",
    "        roads = ox.graph_to_gdfs(ox.graph_from_place(osm_boundary_place, network_type=\"drive\"), nodes=False)\n",
    "        roads = roads.to_crs(epsg=32614)\n",
    "        save_to_cache(roads, \"roads.pkl\", cache_dir)\n",
    "\n",
    "    # Subsample datasets using the bounding box around Corpus Christi center in UTM\n",
    "    print(\"- Subsampling datasets...\")\n",
    "    blocks_subset, buildings_subset, roads_subset = subsample_data(corpus_christi_center_utm, subsample_scale, blocks, buildings, roads)\n",
    "    print(\"- Data loading complete.\")\n",
    "\n",
    "    return blocks_subset, buildings_subset, roads_subset\n",
    "\n",
    "\n",
    "# Define paths to block shapefile and Corpus Christi boundary\n",
    "one_drive_path = read_path_from_file(\"OneDrive.txt\")\n",
    "block_path = os.path.join(one_drive_path, \"Data\", \"tl_2023_48_tabblock20\", \"tl_2023_48_tabblock20.shp\")\n",
    "osm_boundary_place = \"Corpus Christi, Texas, USA\"\n",
    "\n",
    "# Load data with subsampling\n",
    "print(\"Starting data loading...\")\n",
    "blocks_subset, buildings_subset, roads_subset = load_data(block_path, osm_boundary_place, subsample_scale=.5)\n",
    "\n",
    "# Inspect subsampled data\n",
    "print(\"-- Blocks subset:\")\n",
    "print(blocks_subset.head())\n",
    "print(\"-- Buildings subset:\")\n",
    "print(buildings_subset.head())\n",
    "print(\"-- Roads subset:\")\n",
    "print(roads_subset.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc4d38e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available columns in buildings dataset:\n",
      "Index(['geometry', 'addr:state', 'building', 'ele', 'gnis:feature_id', 'name',\n",
      "       'source', 'addr:city', 'addr:housename', 'addr:housenumber',\n",
      "       ...\n",
      "       'female', 'male', 'portable', 'toilets:handwashing', 'capacity', 'size',\n",
      "       'build_idx', 'build_area_sm', 'height_m', 'height_ft'],\n",
      "      dtype='object', length=202)\n",
      "Calculating block metrics...\n",
      "Calculating building area coverage (sq-mile)...\n",
      "Processing building heights...\n",
      "Calculating building setbacks...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael.Barzach\\AppData\\Local\\Temp\\ipykernel_66440\\1702977894.py:37: DeprecationWarning: The 'unary_union' attribute is deprecated, use the 'union_all()' method instead.\n",
      "  roads_union = roads_subset.geometry.unary_union  # Combine all road geometries into one\n",
      "C:\\Users\\Michael.Barzach\\AppData\\Roaming\\Python\\Python311\\site-packages\\geopandas\\geodataframe.py:1819: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  super().__setitem__(key, value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating buildings with blocks via spatial join...\n",
      "Aggregating building metrics per block...\n",
      "Calculating population density and other metrics for blocks...\n",
      "Calculating additional block metrics: Building count per square mile and building area percentage...\n",
      "Merging building metrics into block dataset...\n",
      "Filling missing values for block metrics...\n",
      "Block metrics calculated successfully.\n",
      "Block metrics successfully calculated:\n",
      "  STATEFP20 COUNTYFP20 TRACTCE20 BLOCKCE20          GEOID20  \\\n",
      "0        48        355    001300      4003  483550013004003   \n",
      "1        48        355    001300      4004  483550013004004   \n",
      "2        48        355    001400      1007  483550014001007   \n",
      "3        48        355    001400      1006  483550014001006   \n",
      "4        48        355    001400      1005  483550014001005   \n",
      "\n",
      "                  GEOIDFQ20     NAME20 MTFCC20 UR20 UACE20  ... BLOCK_ID  \\\n",
      "0  1000000US483550013004003  Block4003   G5040    U  20287  ...   211081   \n",
      "1  1000000US483550013004004  Block4004   G5040    U  20287  ...   211082   \n",
      "2  1000000US483550014001007  Block1007   G5040    U  20287  ...   211084   \n",
      "3  1000000US483550014001006  Block1006   G5040    U  20287  ...   211085   \n",
      "4  1000000US483550014001005  Block1005   G5040    U  20287  ...   211086   \n",
      "\n",
      "    area_sm     pop_dens      pop_den   avg_hght  avg_sback  bld_area bld_cnt  \\\n",
      "0  0.009445  8152.607692  8152.607692  32.854718  58.518871  0.001198    17.0   \n",
      "1  0.006603     0.000000     0.000000  32.414699  54.053822  0.002782     1.0   \n",
      "2  0.005841   513.624735   513.624735  36.269686  31.704581  0.001315     4.0   \n",
      "3  0.002102     0.000000     0.000000  35.482285  28.367179  0.000416     2.0   \n",
      "4  0.000797     0.000000     0.000000   0.000000   0.000000  0.000000     0.0   \n",
      "\n",
      "      bld_ctsm    bld_prc  \n",
      "0  1799.926373  12.688341  \n",
      "1   151.448236  42.140090  \n",
      "2   684.832979  22.512402  \n",
      "3   951.312857  19.800931  \n",
      "4     0.000000   0.000000  \n",
      "\n",
      "[5 rows x 28 columns]\n"
     ]
    }
   ],
   "source": [
    "def calculate_block_metrics(blocks_subset: gpd.GeoDataFrame, buildings_subset: gpd.GeoDataFrame, roads_subset: gpd.GeoDataFrame) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Calculate block-level metrics\n",
    "    \"\"\"\n",
    "    print(\"Available columns in buildings dataset:\")\n",
    "    print(buildings_subset.columns)\n",
    "\n",
    "    # Check if required columns exist in the buildings dataset\n",
    "    required_columns = [\"geometry\", \"height\"]\n",
    "    missing_columns = [col for col in required_columns if col not in buildings_subset.columns]\n",
    "    if missing_columns:\n",
    "        print(f\"Error: Missing required columns in buildings dataset: {missing_columns}\")\n",
    "        print(\"Preview of buildings dataset:\")\n",
    "        print(buildings_subset.head())\n",
    "        raise KeyError(f\"Required columns {missing_columns} are not found in buildings dataset.\")\n",
    "\n",
    "    print(\"Calculating block metrics...\")\n",
    "    blocks_subset[\"BLOCK_ID\"] = blocks_subset.index  # Assign unique ID to each block\n",
    "    buildings_subset[\"build_idx\"] = buildings_subset.index  # Assign unique ID to each building\n",
    "\n",
    "    # Calculate building area (square meters -> square miles)\n",
    "    print(\"Calculating building area coverage (sq-mile)...\")\n",
    "    buildings_subset[\"build_area_sm\"] = buildings_subset.geometry.area * 0.00000038610215855  # Convert area to sq-mile\n",
    "\n",
    "    # Handle building height (convert meters to feet and filter valid heights)\n",
    "    print(\"Processing building heights...\")\n",
    "    buildings_subset[\"height_m\"] = pd.to_numeric(buildings_subset[\"height\"], errors=\"coerce\")\n",
    "    buildings_subset[\"height_ft\"] = buildings_subset[\"height_m\"] * 3.28084  # Convert height to feet\n",
    "    buildings_subset = buildings_subset[buildings_subset[\"height_ft\"] > 0]  # Filter buildings with positive heights\n",
    "\n",
    "    # Calculate building setbacks (distance to nearest road)\n",
    "    print(\"Calculating building setbacks...\")\n",
    "    roads_union = roads_subset.geometry.unary_union  # Combine all road geometries into one\n",
    "    buildings_subset[\"setback_ft\"] = buildings_subset.geometry.apply(\n",
    "        lambda building_geom: building_geom.distance(roads_union) * 3.28084  # Convert meters to feet\n",
    "    )\n",
    "\n",
    "    # Spatial join to associate buildings with blocks\n",
    "    print(\"Associating buildings with blocks via spatial join...\")\n",
    "    buildings_with_blocks = gpd.sjoin(buildings_subset, blocks_subset, how=\"inner\", predicate=\"intersects\")\n",
    "\n",
    "    # Aggregate metrics per block\n",
    "    print(\"Aggregating building metrics per block...\")\n",
    "    building_metrics = buildings_with_blocks.groupby(\"BLOCK_ID\").agg(\n",
    "        avg_hght=(\"height_ft\", \"mean\"),  # Renamed: Average building height\n",
    "        avg_sback=(\"setback_ft\", \"mean\"),  # Renamed: Average setback distance\n",
    "        bld_area=(\"build_area_sm\", \"sum\"),  # Renamed: Sum building areas\n",
    "        bld_cnt=(\"build_idx\", \"count\"),  # Renamed: Count number of buildings\n",
    "    )\n",
    "\n",
    "    # Calculate population density for blocks\n",
    "    print(\"Calculating population density and other metrics for blocks...\")\n",
    "    blocks_subset[\"area_sm\"] = blocks_subset.geometry.area * 0.00000038610215855  # Convert block area to sq-mile\n",
    "    blocks_subset[\"pop_den\"] = blocks_subset[\"POP20\"] / blocks_subset[\"area_sm\"]  # Renamed: Population density per sq-mile\n",
    "\n",
    "    # Derive additional metrics\n",
    "    print(\"Calculating additional block metrics: Building count per square mile and building area percentage...\")\n",
    "    building_metrics[\"bld_ctsm\"] = building_metrics[\"bld_cnt\"] / blocks_subset[\"area_sm\"]  # Renamed: Building count per sq-mile\n",
    "    building_metrics[\"bld_prc\"] = (building_metrics[\"bld_area\"] / blocks_subset[\"area_sm\"]) * 100  # Renamed: Building area as percentage of block area\n",
    "\n",
    "    # Merge metrics into block dataset\n",
    "    print(\"Merging building metrics into block dataset...\")\n",
    "    blocks_subset = blocks_subset.merge(building_metrics, on=\"BLOCK_ID\", how=\"left\")\n",
    "\n",
    "    # Fill missing values explicitly for columns\n",
    "    print(\"Filling missing values for block metrics...\")\n",
    "    blocks_subset[\"avg_hght\"] = blocks_subset[\"avg_hght\"].fillna(0)  # Replace NaN with 0\n",
    "    blocks_subset[\"avg_sback\"] = blocks_subset[\"avg_sback\"].fillna(0)  # Replace NaN with 0\n",
    "    blocks_subset[\"bld_area\"] = blocks_subset[\"bld_area\"].fillna(0)  # Replace NaN with 0\n",
    "    blocks_subset[\"bld_ctsm\"] = blocks_subset[\"bld_ctsm\"].fillna(0)  # Replace NaN with 0\n",
    "    blocks_subset[\"bld_prc\"] = blocks_subset[\"bld_prc\"].fillna(0)  # Replace NaN with 0\n",
    "    blocks_subset[\"bld_cnt\"] = blocks_subset[\"bld_cnt\"].fillna(0)  # Replace NaN with 0\n",
    "\n",
    "    print(\"Block metrics calculated successfully.\")\n",
    "    return blocks_subset\n",
    "\n",
    "# Calculate block-level metrics\n",
    "blocks_processed = calculate_block_metrics(blocks_subset, buildings_subset, roads_subset)\n",
    "print(\"Block metrics successfully calculated:\")\n",
    "print(blocks_processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48683f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Calculating road metrics with buffer size (for spatial analysis): 50 feet...\n",
      "- Assigning unique IDs to blocks and roads...\n",
      "-- Inspecting blocks structure before processing:\n",
      "Index(['STATEFP20', 'COUNTYFP20', 'TRACTCE20', 'BLOCKCE20', 'GEOID20',\n",
      "       'GEOIDFQ20', 'NAME20', 'MTFCC20', 'UR20', 'UACE20', 'FUNCSTAT20',\n",
      "       'ALAND20', 'AWATER20', 'INTPTLAT20', 'INTPTLON20', 'HOUSING20', 'POP20',\n",
      "       'geometry', 'BLOCK_ID', 'area_sm', 'pop_dens', 'pop_den', 'avg_hght',\n",
      "       'avg_sback', 'bld_area', 'bld_cnt', 'bld_ctsm', 'bld_prc', 'block_id'],\n",
      "      dtype='object')\n",
      "  STATEFP20 COUNTYFP20 TRACTCE20 BLOCKCE20          GEOID20  \\\n",
      "0        48        355    001300      4003  483550013004003   \n",
      "1        48        355    001300      4004  483550013004004   \n",
      "2        48        355    001400      1007  483550014001007   \n",
      "3        48        355    001400      1006  483550014001006   \n",
      "4        48        355    001400      1005  483550014001005   \n",
      "\n",
      "                  GEOIDFQ20     NAME20 MTFCC20 UR20 UACE20  ...   area_sm  \\\n",
      "0  1000000US483550013004003  Block4003   G5040    U  20287  ...  0.009445   \n",
      "1  1000000US483550013004004  Block4004   G5040    U  20287  ...  0.006603   \n",
      "2  1000000US483550014001007  Block1007   G5040    U  20287  ...  0.005841   \n",
      "3  1000000US483550014001006  Block1006   G5040    U  20287  ...  0.002102   \n",
      "4  1000000US483550014001005  Block1005   G5040    U  20287  ...  0.000797   \n",
      "\n",
      "      pop_dens      pop_den   avg_hght  avg_sback  bld_area  bld_cnt  \\\n",
      "0  8152.607692  8152.607692  32.854718  58.518871  0.001198     17.0   \n",
      "1     0.000000     0.000000  32.414699  54.053822  0.002782      1.0   \n",
      "2   513.624735   513.624735  36.269686  31.704581  0.001315      4.0   \n",
      "3     0.000000     0.000000  35.482285  28.367179  0.000416      2.0   \n",
      "4     0.000000     0.000000   0.000000   0.000000  0.000000      0.0   \n",
      "\n",
      "      bld_ctsm    bld_prc  block_id  \n",
      "0  1799.926373  12.688341         0  \n",
      "1   151.448236  42.140090         1  \n",
      "2   684.832979  22.512402         2  \n",
      "3   951.312857  19.800931         3  \n",
      "4     0.000000   0.000000         4  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "- Creating road buffers...\n",
      "-- Road buffers structure after buffering:\n",
      "Index(['osmid', 'highway', 'lanes', 'name', 'oneway', 'ref', 'reversed',\n",
      "       'length', 'maxspeed', 'geometry', 'bridge', 'junction', 'width',\n",
      "       'access', 'original_geometry', 'road_id'],\n",
      "      dtype='object')\n",
      "- Performing spatial join of blocks with road buffers...\n",
      "-- Intersections structure after spatial join:\n",
      "  STATEFP20 COUNTYFP20 TRACTCE20 BLOCKCE20          GEOID20  \\\n",
      "0        48        355    001300      4003  483550013004003   \n",
      "1        48        355    001300      2013  483550013002013   \n",
      "2        48        355    001300      2010  483550013002010   \n",
      "3        48        355    001300      4002  483550013004002   \n",
      "4        48        355    001300      2011  483550013002011   \n",
      "\n",
      "                  GEOIDFQ20     NAME20 MTFCC20 UR20 UACE20  ... reversed  \\\n",
      "0  1000000US483550013004003  Block4003   G5040    U  20287  ...    False   \n",
      "1  1000000US483550013002013  Block2013   G5040    U  20287  ...    False   \n",
      "2  1000000US483550013002010  Block2010   G5040    U  20287  ...    False   \n",
      "3  1000000US483550013004002  Block4002   G5040    U  20287  ...    False   \n",
      "4  1000000US483550013002011  Block2011   G5040    U  20287  ...    False   \n",
      "\n",
      "       length  maxspeed bridge junction  width  access  \\\n",
      "0  259.875325       NaN    NaN      NaN    NaN     NaN   \n",
      "1  259.875325       NaN    NaN      NaN    NaN     NaN   \n",
      "2  259.875325       NaN    NaN      NaN    NaN     NaN   \n",
      "3  259.875325       NaN    NaN      NaN    NaN     NaN   \n",
      "4  259.875325       NaN    NaN      NaN    NaN     NaN   \n",
      "\n",
      "                                   original_geometry  road_id  \\\n",
      "0  LINESTRING (656995.944 3073074.001, 657132.059...      712   \n",
      "1  LINESTRING (656995.944 3073074.001, 657132.059...      712   \n",
      "2  LINESTRING (656995.944 3073074.001, 657132.059...      712   \n",
      "3  LINESTRING (656995.944 3073074.001, 657132.059...      712   \n",
      "4  LINESTRING (656995.944 3073074.001, 657132.059...      712   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((657129.179 3072849.612, 657133.578 3...  \n",
      "1  POLYGON ((657133.578 3072852.439, 657106.188 3...  \n",
      "2  POLYGON ((656996.237 3073075.722, 656988.944 3...  \n",
      "3  POLYGON ((657133.578 3072852.439, 657145.758 3...  \n",
      "4  POLYGON ((656996.237 3073075.722, 656982.49 30...  \n",
      "\n",
      "[5 rows x 44 columns]\n",
      "-- Validating `block_area` and recalculating if needed...\n",
      "-- Intersection overlap proportions sample:\n",
      "   block_id  road_id  overlap_area    block_area  overlap_proportion\n",
      "0         0      712    168.652836  24461.999404            0.006894\n",
      "1       115      712   3729.088975  25527.143071            0.146083\n",
      "2       127      712    146.038153  25747.555687            0.005672\n",
      "3       245      712    147.718173  25343.343902            0.005829\n",
      "4       385      712    180.673840  25807.763451            0.007001\n",
      "- Creating overlap dictionary for roads...\n",
      "-- Road-block overlap dictionary sample:\n",
      "Road ID 0: {483: 0.015555468895943045, 484: 0.06787825537214592, 486: 0.008790046465988579, 489: 0.06708928489227088}\n",
      "Road ID 1: {104: 0.00672684170098161, 483: 0.03678591524781138, 484: 0.015561584309722593, 489: 0.01080238912914177}\n",
      "Road ID 2: {62: 0.005091677094137467, 367: 0.011208897415474322, 483: 0.05489523796962245, 484: 0.005808666693117616, 489: 0.024114432520056267}\n",
      "Road ID 3: {484: 0.09382057750007784, 486: 0.14584958623093353, 487: 0.03515100355131997, 489: 0.0084860124823746}\n",
      "Road ID 4: {149: 0.0133656694076713, 484: 0.012473326609076067, 486: 0.17074410109364319, 489: 0.08824981716021409, 490: 0.0038022377596832807}\n",
      "- Weighting metrics for roads...\n",
      "- Aggregating weighted metrics across roads...\n",
      "-- Aggregated road metrics structure:\n",
      "       agg_pop  agg_area    agg_ctsm  agg_hght  agg_sback\n",
      "0   633.771855  0.000234  380.793736  5.376044   9.384688\n",
      "1   150.525101  0.000093  155.941690  2.398480   3.332964\n",
      "2   114.554238  0.000132  196.531501  3.544911   4.602782\n",
      "3  2802.432397  0.000297  887.392716  8.697738  16.520065\n",
      "4  2738.123769  0.000341  805.463552  9.263241  17.227443\n",
      "- Merging metrics into roads dataset...\n",
      "-- Final roads structure:\n",
      "       osmid      highway lanes             name  oneway  ref reversed  \\\n",
      "0   21145794     tertiary   NaN  Highland Avenue   False  NaN    False   \n",
      "1  371318831  residential   NaN      Ruth Street   False  NaN    False   \n",
      "2  371318832     tertiary   NaN      Ruth Street   False  NaN     True   \n",
      "3   21145794     tertiary   NaN  Highland Avenue   False  NaN    False   \n",
      "4   21160049  residential   NaN  Hibiscus Street   False  NaN    False   \n",
      "\n",
      "       length maxspeed                                           geometry  \\\n",
      "0  117.941931      NaN  LINESTRING (655587.283 3074123.505, 655546.617...   \n",
      "1   26.240267      NaN  LINESTRING (655587.283 3074123.505, 655575.176...   \n",
      "2   42.143124      NaN  LINESTRING (655587.283 3074123.505, 655604.94 ...   \n",
      "3  152.238928      NaN  LINESTRING (655495.562 3074049.411, 655374.926...   \n",
      "4  166.763729      NaN  LINESTRING (655495.562 3074049.411, 655501.252...   \n",
      "\n",
      "   ... junction width access  \\\n",
      "0  ...      NaN   NaN    NaN   \n",
      "1  ...      NaN   NaN    NaN   \n",
      "2  ...      NaN   NaN    NaN   \n",
      "3  ...      NaN   NaN    NaN   \n",
      "4  ...      NaN   NaN    NaN   \n",
      "\n",
      "                                   original_geometry road_id      agg_pop  \\\n",
      "0  LINESTRING (655587.283 3074123.505, 655546.617...       0   633.771855   \n",
      "1  LINESTRING (655587.283 3074123.505, 655575.176...       1   150.525101   \n",
      "2  LINESTRING (655587.283 3074123.505, 655604.94 ...       2   114.554238   \n",
      "3  LINESTRING (655495.562 3074049.411, 655374.926...       3  2802.432397   \n",
      "4  LINESTRING (655495.562 3074049.411, 655501.252...       4  2738.123769   \n",
      "\n",
      "   agg_area    agg_ctsm  agg_hght  agg_sback  \n",
      "0  0.000234  380.793736  5.376044   9.384688  \n",
      "1  0.000093  155.941690  2.398480   3.332964  \n",
      "2  0.000132  196.531501  3.544911   4.602782  \n",
      "3  0.000297  887.392716  8.697738  16.520065  \n",
      "4  0.000341  805.463552  9.263241  17.227443  \n",
      "\n",
      "[5 rows x 21 columns]\n",
      "-- Final processed roads sample:\n",
      "       osmid      highway lanes             name  oneway  ref reversed  \\\n",
      "0   21145794     tertiary   NaN  Highland Avenue   False  NaN    False   \n",
      "1  371318831  residential   NaN      Ruth Street   False  NaN    False   \n",
      "2  371318832     tertiary   NaN      Ruth Street   False  NaN     True   \n",
      "3   21145794     tertiary   NaN  Highland Avenue   False  NaN    False   \n",
      "4   21160049  residential   NaN  Hibiscus Street   False  NaN    False   \n",
      "\n",
      "       length maxspeed                                           geometry  \\\n",
      "0  117.941931      NaN  LINESTRING (655587.283 3074123.505, 655546.617...   \n",
      "1   26.240267      NaN  LINESTRING (655587.283 3074123.505, 655575.176...   \n",
      "2   42.143124      NaN  LINESTRING (655587.283 3074123.505, 655604.94 ...   \n",
      "3  152.238928      NaN  LINESTRING (655495.562 3074049.411, 655374.926...   \n",
      "4  166.763729      NaN  LINESTRING (655495.562 3074049.411, 655501.252...   \n",
      "\n",
      "   ... junction width access  \\\n",
      "0  ...      NaN   NaN    NaN   \n",
      "1  ...      NaN   NaN    NaN   \n",
      "2  ...      NaN   NaN    NaN   \n",
      "3  ...      NaN   NaN    NaN   \n",
      "4  ...      NaN   NaN    NaN   \n",
      "\n",
      "                                   original_geometry road_id      agg_pop  \\\n",
      "0  LINESTRING (655587.283 3074123.505, 655546.617...       0   633.771855   \n",
      "1  LINESTRING (655587.283 3074123.505, 655575.176...       1   150.525101   \n",
      "2  LINESTRING (655587.283 3074123.505, 655604.94 ...       2   114.554238   \n",
      "3  LINESTRING (655495.562 3074049.411, 655374.926...       3  2802.432397   \n",
      "4  LINESTRING (655495.562 3074049.411, 655501.252...       4  2738.123769   \n",
      "\n",
      "   agg_area    agg_ctsm  agg_hght  agg_sback  \n",
      "0  0.000234  380.793736  5.376044   9.384688  \n",
      "1  0.000093  155.941690  2.398480   3.332964  \n",
      "2  0.000132  196.531501  3.544911   4.602782  \n",
      "3  0.000297  887.392716  8.697738  16.520065  \n",
      "4  0.000341  805.463552  9.263241  17.227443  \n",
      "\n",
      "[5 rows x 21 columns]\n"
     ]
    }
   ],
   "source": [
    "def calculate_road_metrics(blocks_subset: gpd.GeoDataFrame, roads_subset: gpd.GeoDataFrame, buffer_size_feet=50) -> gpd.GeoDataFrame:\n",
    "    \"\"\"\n",
    "    Calculate road-level metrics based on spatial overlap with blocks (weighted aggregation).\n",
    "    \"\"\"\n",
    "    print(f\"- Calculating road metrics with buffer size (for spatial analysis): {buffer_size_feet} feet...\")\n",
    "    \n",
    "    buffer_size_meters = buffer_size_feet * 0.3048  # Convert buffer size to meters\n",
    "\n",
    "    # Ensure unique IDs for blocks and roads\n",
    "    print(\"- Assigning unique IDs to blocks and roads...\")\n",
    "    blocks_subset = blocks_subset.copy().reset_index(drop=True)\n",
    "    blocks_subset[\"block_id\"] = blocks_subset.index\n",
    "\n",
    "    roads_subset = roads_subset.copy().reset_index(drop=True)\n",
    "    roads_subset[\"road_id\"] = roads_subset.index\n",
    "\n",
    "    # Debugging: Inspect blocks\n",
    "    print(\"-- Inspecting blocks structure before processing:\")\n",
    "    print(blocks_subset.columns)\n",
    "    print(blocks_subset.head())  # Output a sample of blocks_subset\n",
    "\n",
    "    # Check if required block-level metrics exist\n",
    "    required_columns = [\"area_sm\", \"pop_den\", \"bld_area\", \"bld_ctsm\", \"avg_hght\", \"avg_sback\"]\n",
    "    missing_columns = [col for col in required_columns if col not in blocks_subset.columns]\n",
    "    if missing_columns:\n",
    "        print(f\"ERROR: The following required block-level metrics are missing: {missing_columns}\")\n",
    "        print(\"-- Full blocks_subset structure for debugging:\")\n",
    "        print(blocks_subset.head())\n",
    "        raise KeyError(f\"Missing required columns in blocks_subset: {missing_columns}\")\n",
    "\n",
    "    # Create buffers for roads\n",
    "    print(\"- Creating road buffers...\")\n",
    "    road_buffers = roads_subset.copy()\n",
    "    road_buffers[\"geometry\"] = roads_subset.geometry.buffer(buffer_size_meters)\n",
    "    road_buffers[\"road_id\"] = roads_subset[\"road_id\"]\n",
    "\n",
    "    print(\"-- Road buffers structure after buffering:\")\n",
    "    print(road_buffers.columns)\n",
    "\n",
    "    # Perform spatial join to calculate intersections with blocks\n",
    "    print(\"- Performing spatial join of blocks with road buffers...\")\n",
    "    intersections = gpd.overlay(blocks_subset, road_buffers, how=\"intersection\")\n",
    "\n",
    "    print(\"-- Intersections structure after spatial join:\")\n",
    "    print(intersections.head())\n",
    "\n",
    "    # Validate block areas and overlap proportions\n",
    "    print(\"-- Validating `block_area` and recalculating if needed...\")\n",
    "    blocks_subset[\"block_area\"] = blocks_subset.geometry.area\n",
    "    intersections[\"block_area\"] = intersections[\"block_id\"].map(blocks_subset.set_index(\"block_id\")[\"block_area\"])\n",
    "    intersections[\"overlap_area\"] = intersections.geometry.area\n",
    "    intersections[\"overlap_proportion\"] = intersections[\"overlap_area\"] / intersections[\"block_area\"]\n",
    "\n",
    "    print(\"-- Intersection overlap proportions sample:\")\n",
    "    print(intersections[[\"block_id\", \"road_id\", \"overlap_area\", \"block_area\", \"overlap_proportion\"]].head())\n",
    "\n",
    "    # Create overlap dictionary for roads\n",
    "    print(\"- Creating overlap dictionary for roads...\")\n",
    "    road_block_overlap = (\n",
    "        intersections.groupby(\"road_id\")\n",
    "        .apply(lambda rows: dict(zip(rows[\"block_id\"], rows[\"overlap_proportion\"])))\n",
    "        .to_dict()\n",
    "    )\n",
    "\n",
    "    print(\"-- Road-block overlap dictionary sample:\")\n",
    "    for road_id in list(road_block_overlap.keys())[:5]:\n",
    "        print(f\"Road ID {road_id}: {road_block_overlap[road_id]}\")\n",
    "\n",
    "    # Calculate weighted metrics for roads\n",
    "    print(\"- Weighting metrics for roads...\")\n",
    "    def compute_weighted_metrics(road_id, overlap_dict):\n",
    "        # Subset relevant blocks using overlap proportions\n",
    "        blocks = blocks_subset.set_index(\"block_id\").loc[overlap_dict.keys()]\n",
    "        weights = pd.Series({block_id: overlap_dict[block_id] for block_id in blocks.index})  # Use overlap proportions\n",
    "\n",
    "        # Separate filtering for aggregated height and setback\n",
    "        valid_blocks_for_hght_sback = blocks[(blocks[\"avg_hght\"] > 0) & (blocks[\"avg_sback\"] > 0)]\n",
    "\n",
    "        aggregated_metrics = {\n",
    "            # Include all blocks for these calculations\n",
    "            \"agg_pop\": (blocks[\"pop_den\"] * weights).sum(),  # Aggregated population density\n",
    "            \"agg_area\": (blocks[\"bld_area\"] * weights).sum(),  # Aggregated building area\n",
    "            \"agg_ctsm\": (blocks[\"bld_ctsm\"] * weights).sum(),  # Aggregated building count per sq-mile\n",
    "\n",
    "            # Only include blocks with non-zero avg_hght and avg_sback for these calculations\n",
    "            \"agg_hght\": (valid_blocks_for_hght_sback[\"avg_hght\"] * weights.loc[valid_blocks_for_hght_sback.index]).sum(),\n",
    "            \"agg_sback\": (valid_blocks_for_hght_sback[\"avg_sback\"] * weights.loc[valid_blocks_for_hght_sback.index]).sum(),\n",
    "        }\n",
    "\n",
    "        return pd.Series(aggregated_metrics)\n",
    "\n",
    "    print(\"- Aggregating weighted metrics across roads...\")\n",
    "    road_metrics_df = pd.DataFrame([\n",
    "        compute_weighted_metrics(road_id, overlap_dict)\n",
    "        for road_id, overlap_dict in road_block_overlap.items()\n",
    "    ], index=road_block_overlap.keys())\n",
    "\n",
    "    print(\"-- Aggregated road metrics structure:\")\n",
    "    print(road_metrics_df.head())\n",
    "\n",
    "    # Merge aggregated metrics into roads dataset\n",
    "    print(\"- Merging metrics into roads dataset...\")\n",
    "    roads_subset = roads_subset.merge(road_metrics_df, left_on=\"road_id\", right_index=True, how=\"left\")\n",
    "    roads_subset[\"geometry\"] = roads_subset[\"original_geometry\"]  # Set original geometry as active geometry\n",
    "\n",
    "    print(\"-- Final roads structure:\")\n",
    "    print(roads_subset.head())\n",
    "    return roads_subset\n",
    "\n",
    "\n",
    "# Execute road metrics calculation\n",
    "roads_processed = calculate_road_metrics(blocks_processed, roads_subset, buffer_size_feet=50)\n",
    "print(\"-- Final processed roads sample:\")\n",
    "print(roads_processed.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200fceb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving subsets to shapefiles...\n",
      "- Saving buildings subset...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael.Barzach\\AppData\\Local\\Temp\\ipykernel_66440\\2642583163.py:43: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  buildings_subset.to_file(f\"{output_dir}/Corpus_Christi_buildings_subset.shp\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Saving blocks processed...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael.Barzach\\AppData\\Local\\Temp\\ipykernel_66440\\2642583163.py:48: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  blocks_processed.to_file(f\"{output_dir}/Corpus_Christi_blocks_processed.shp\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Saving roads processed using 'original_geometry' as the active geometry column...\n",
      "-- Using 'original_geometry' as the geometry column.\n",
      "-- Dropping the 'geometry' column.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Michael.Barzach\\AppData\\Local\\Temp\\ipykernel_66440\\2642583163.py:68: UserWarning: Column names longer than 10 characters will be truncated when saved to ESRI Shapefile.\n",
      "  roads_processed.to_file(f\"{output_dir}/Corpus_Christi_roads_processed.shp\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapefiles saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "import os\n",
    "\n",
    "def save_shapefiles(buildings_subset, blocks_processed, roads_processed, output_dir=\"output\"):\n",
    "    \"\"\"\n",
    "    Save GeoDataFrames to shapefiles while ensuring the correct geometry column is activated.\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(\"Saving subsets to shapefiles...\")\n",
    "\n",
    "    # Suppress warnings\n",
    "    warnings.filterwarnings(\"ignore\", message=\".*Normalized/laundered field name.*\", category=RuntimeWarning)\n",
    "\n",
    "    def ensure_unique_column_names(df, name):\n",
    "        \"\"\"\n",
    "        Ensure column names in a GeoDataFrame are unique by appending trailing numbers to duplicates.\n",
    "        \"\"\"\n",
    "        duplicates = df.columns[df.columns.duplicated()].unique()\n",
    "        if len(duplicates) > 0:\n",
    "            print(f\"WARNING: Duplicate column names detected in {name}: {duplicates}\")\n",
    "            df = df.rename(columns=lambda x: x[:10])  # Truncate names to first 10 characters\n",
    "            # Resolve duplicates by appending a suffix\n",
    "            seen = set()\n",
    "            new_columns = []\n",
    "            for col in df.columns:\n",
    "                if col in seen:\n",
    "                    count = sum([existing.startswith(col) for existing in seen]) + 1\n",
    "                    new_col = f\"{col[:7]}_{count}\"  # Add numeric suffix to resolve duplicates\n",
    "                    print(f\"    Renaming column '{col}' to '{new_col}' to resolve duplication.\")\n",
    "                    new_columns.append(new_col)\n",
    "                else:\n",
    "                    new_columns.append(col)\n",
    "                seen.add(new_columns[-1])\n",
    "            df.columns = new_columns\n",
    "        return df\n",
    "\n",
    "    # Save buildings subset\n",
    "    print(\"- Saving buildings subset...\")\n",
    "    buildings_subset = ensure_unique_column_names(buildings_subset, \"buildings_subset\")\n",
    "    buildings_subset.to_file(f\"{output_dir}/Corpus_Christi_buildings_subset.shp\")\n",
    "\n",
    "    # Save blocks subset\n",
    "    print(\"- Saving blocks processed...\")\n",
    "    blocks_processed = ensure_unique_column_names(blocks_processed, \"blocks_processed\")\n",
    "    blocks_processed.to_file(f\"{output_dir}/Corpus_Christi_blocks_processed.shp\")\n",
    "\n",
    "    # Save roads subset \n",
    "    print(\"- Saving roads processed using 'original_geometry' as the active geometry column...\")\n",
    "\n",
    "    # Activate `original_geometry` as the geometry column and drop `geometry`\n",
    "    if \"original_geometry\" in roads_processed.columns:\n",
    "        print(\"-- Using 'original_geometry' as the geometry column.\")\n",
    "        roads_processed = roads_processed.set_geometry(\"original_geometry\")  # Use original_geometry for geometry\n",
    "    else:\n",
    "        raise ValueError(\"ERROR: 'original_geometry' column is missing in roads_processed!\")\n",
    "\n",
    "    if \"geometry\" in roads_processed.columns:\n",
    "        print(\"-- Dropping the 'geometry' column.\")\n",
    "        roads_processed = roads_processed.drop(columns=[\"geometry\"])\n",
    "\n",
    "    # Ensure unique column names for roads_processed\n",
    "    roads_processed = ensure_unique_column_names(roads_processed, \"roads_processed\")\n",
    "\n",
    "    # Save the roads GeoDataFrame\n",
    "    roads_processed.to_file(f\"{output_dir}/Corpus_Christi_roads_processed.shp\")\n",
    "\n",
    "    print(\"Shapefiles saved successfully.\")\n",
    "\n",
    "# Save the processed data to shapefiles\n",
    "save_shapefiles(buildings_subset, blocks_processed, roads_processed, output_dir=\"output\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
